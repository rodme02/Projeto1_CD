{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Vitor Fortes Giuliano Riccetti \n",
    "\n",
    "Nome: Rodrigo Paoliello de Medeiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Chuteira_Puma.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Chuteira_Puma.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a leitura do excel \n",
    "train = pd.read_excel(filename, sheet_name = 'Treinamento')\n",
    "train.head(5)\n",
    "\n",
    "train[\"Relevante\"]= train[\"Relevante\"].astype(str)\n",
    "train[\"Irrelevante\"]= train[\"Irrelevante\"].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@gathlos de níver atrasado quero uma chuteira ...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@neymarjrdepre @neymarjr @puma essa chuteira é...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>era só essa chuteira da puma na minha vida</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@manassescruz1 @juancrf19 @futebol_info @puma_...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>só a chuteira da puma na minha vida mesmo.</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste classificacao\n",
       "0  @gathlos de níver atrasado quero uma chuteira ...     Relevante\n",
       "1  @neymarjrdepre @neymarjr @puma essa chuteira é...     Relevante\n",
       "2         era só essa chuteira da puma na minha vida     Relevante\n",
       "3  @manassescruz1 @juancrf19 @futebol_info @puma_...     Relevante\n",
       "4         só a chuteira da puma na minha vida mesmo.     Relevante"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividimos em duas categorias relevante e irrelevante:\n",
    "\n",
    "Relevantes = ''.join(train.Relevante)\n",
    "\n",
    "Irrelevantes = ' '.join(train.Irrelevante)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpar a string\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    text = re.sub(r'@\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'_', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'kk\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'https\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    punctuation = '[!-.:?;_“”]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "emoji_pat = '[\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "shrink_whitespace_reg = re.compile(r'\\s{2,}')\n",
    "\n",
    "def clean_text(text_subbed):\n",
    "    reg = re.compile(r'({})'.format(emoji_pat)) # line a\n",
    "    result = reg.sub(lambda x: ' {} '.format(x.group(1)) if x.group(1) else ' ', text_subbed)\n",
    "    return shrink_whitespace_reg.sub(' ', result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retira as pontuações e os links\n",
    "\n",
    "Lista_R_clean = cleanup(Relevantes.lower())\n",
    "Lista_R_clean = clean_text(Lista_R_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retira as pontuações e os links\n",
    "\n",
    "Lista_IR_clean = cleanup(Irrelevantes.lower())\n",
    "Lista_IR_clean = clean_text(Lista_IR_clean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serie de palavras Relevantes\n",
    "Palavras_relevantes = pd.Series(Lista_R_clean.split())\n",
    "\n",
    "len(Palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2105"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serie de palavras Irrelevantes\n",
    "Palavras_irrelevantes = pd.Series(Lista_IR_clean.split())\n",
    "\n",
    "len(Palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela absoluta dos Relevantes.\n",
    "tabela_absoluta_relevantes = Palavras_relevantes.value_counts(ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela absoluta dos Irrelevantes.\n",
    "tabela_absoluta_irrelevantes = Palavras_irrelevantes.value_counts(ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequencia relativa dos Relevantes \n",
    "\n",
    "tabela_relativa_relevantes = Palavras_relevantes.value_counts(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_relevantes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencia relativa dos Irrelevantes\n",
    "\n",
    "tabela_relativa_irrelevantes = Palavras_irrelevantes.value_counts(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relativa_irrelevantes.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4552277432712215\n",
      "0.5447722567287785\n"
     ]
    }
   ],
   "source": [
    "total = len(Palavras_relevantes) + len(Palavras_irrelevantes)\n",
    "total_relevantes = len(Palavras_relevantes)/total\n",
    "total_irrelevantes = len(Palavras_irrelevantes)/total\n",
    "print(total_relevantes)\n",
    "print(total_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras que nos selecionamos \n",
    "\n",
    "lista_palavras = ['chuteira','bonita','feia','quero','comprar','não','gostei','ruim','boa','puma','nike','adidas','melhor','neymar','estranho']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade das palavras estarem como relevantes \n",
    "\n",
    "chuteira_r = (tabela_absoluta_relevantes['chuteira'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "bonita_r = (tabela_absoluta_relevantes['bonita'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "feia_r = (tabela_absoluta_relevantes['feia'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "quero_r = (tabela_absoluta_relevantes['quero'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "comprar_r = (tabela_absoluta_relevantes['comprar'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "nao_r = (tabela_absoluta_relevantes['não'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "gostei_r = (tabela_absoluta_relevantes['gostei'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "ruim_r = (tabela_absoluta_relevantes['ruim'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "boa_r = (tabela_absoluta_relevantes['boa'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "puma_r = (tabela_absoluta_relevantes['puma'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "nike_r = (tabela_absoluta_relevantes['nike'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "adidas_r = (tabela_absoluta_relevantes['adidas'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "melhor_r = (tabela_absoluta_relevantes['melhor'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "neymar_r = (tabela_absoluta_relevantes['neymar'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "estranho_r = (tabela_absoluta_relevantes['estranho'] + 1)/(len(Palavras_relevantes) + len(lista_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidade das palavras estarem como irrelevantes \n",
    "\n",
    "chuteira_ir = (tabela_absoluta_irrelevantes['chuteira'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "bonita_ir = (tabela_absoluta_irrelevantes['bonita'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "feia_ir = (tabela_absoluta_irrelevantes['feia'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "quero_ir = (tabela_absoluta_irrelevantes['quero'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "comprar_ir = (tabela_absoluta_irrelevantes['comprar'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "nao_ir = (tabela_absoluta_irrelevantes['não'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "gostei_ir = (tabela_absoluta_irrelevantes['gostei'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "ruim_ir = (0 + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "boa_ir = (tabela_absoluta_irrelevantes['boa'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "puma_ir = (tabela_absoluta_irrelevantes['puma'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "nike_ir = (tabela_absoluta_irrelevantes['nike'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "adidas_ir = (tabela_absoluta_irrelevantes['adidas'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "melhor_ir = (tabela_absoluta_irrelevantes['melhor'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "neymar_ir = (tabela_absoluta_irrelevantes['neymar'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "estranho_ir = (tabela_absoluta_irrelevantes['estranho'] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001397328822055775"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_chuteira_bonita_r = chuteira_r * bonita_r * total_relevantes\n",
    "P_chuteira_bonita_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.757551610580307e-05"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_chuteira_bonita_ir = chuteira_ir * bonita_ir * total_irrelevantes\n",
    "P_chuteira_bonita_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000279465764411155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_chuteira_feia_r = chuteira_r * feia_r * total_relevantes\n",
    "P_chuteira_feia_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.757551610580307e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_chuteira_feia_ir = chuteira_ir * feia_ir * total_irrelevantes\n",
    "P_chuteira_feia_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.73874777942056e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_quero_comprar_chuteira_r = quero_r * comprar_r * chuteira_r * total_relevantes\n",
    "P_quero_comprar_chuteira_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0634580029944266e-07"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_quero_comprar_chuteira_ir = quero_ir * comprar_ir * chuteira_ir * total_irrelevantes\n",
    "P_quero_comprar_chuteira_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.773483553606684e-06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nike_melhor_r = nike_r * melhor_r * total_relevantes\n",
    "P_nike_melhor_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0181752751249865e-05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_nike_melhor_ir = nike_ir * melhor_ir * total_irrelevantes\n",
    "P_nike_melhor_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3018591509836412e-06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_adidas_melhor_r = adidas_r * melhor_r * total_relevantes\n",
    "P_adidas_melhor_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.939381476428546e-06"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_adidas_melhor_ir = adidas_ir * melhor_ir * total_irrelevantes\n",
    "P_adidas_melhor_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0769734153314575e-07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_neymar_puma_estranho_r = neymar_r * puma_r * estranho_r * total_relevantes\n",
    "P_neymar_puma_estranho_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2291451946638017e-06"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_neymar_puma_estranho_ir = neymar_ir * puma_ir * estranho_ir * total_irrelevantes\n",
    "P_neymar_puma_estranho_ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Irrelevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Relevante', 'Irrelevante', 'Relevante']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "frase_testes = []\n",
    "classificador = []\n",
    "\n",
    "for tweet in test.Teste:\n",
    "    y = cleanup(tweet.lower())\n",
    "    tweets = clean_text(y)\n",
    "    r = 1\n",
    "    i = 1\n",
    " \n",
    "    for x in tweets:\n",
    "        \n",
    "        if x not in tabela_absoluta_relevantes:\n",
    "            r = r * (0 + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "        else:\n",
    "            r = r *  (tabela_absoluta_relevantes[x] + 1)/(len(Palavras_relevantes) + len(lista_palavras))\n",
    "        if x not in tabela_absoluta_irrelevantes:\n",
    "            i = i * (0 + 1)/(len(Palavras_irrelevantes) + len(lista_palavras))\n",
    "        else:\n",
    "            i = i * (tabela_absoluta_irrelevantes[x] + 1)/(len(Palavras_irrelevantes) + len(lista_palavras)) \n",
    "            \n",
    "    R = total_relevantes * r\n",
    "    I = total_irrelevantes * i\n",
    "    if R > I: \n",
    "        classificador.append(\"Relevante\")\n",
    "    else:\n",
    "        classificador.append(\"Irrelevante\")\n",
    "\n",
    "\n",
    "        \n",
    "print(classificador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@gathlos de níver atrasado quero uma chuteira ...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@neymarjrdepre @neymarjr @puma essa chuteira é...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>era só essa chuteira da puma na minha vida</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@manassescruz1 @juancrf19 @futebol_info @puma_...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>só a chuteira da puma na minha vida mesmo.</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>no aguardo da proposta milionária na dm pra co...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>puma, chuteira preta hmm\\nfedeu a hexa https:/...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>serase o @neymarjr vai ressarcir meu dinheiro ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>só jogo lixo às 16hrs nessa rodada do br.\\n\\né...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>voces gostaram da nova chuteira do neymar com ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste classificacao  \\\n",
       "0    @gathlos de níver atrasado quero uma chuteira ...     Relevante   \n",
       "1    @neymarjrdepre @neymarjr @puma essa chuteira é...     Relevante   \n",
       "2           era só essa chuteira da puma na minha vida     Relevante   \n",
       "3    @manassescruz1 @juancrf19 @futebol_info @puma_...     Relevante   \n",
       "4           só a chuteira da puma na minha vida mesmo.     Relevante   \n",
       "..                                                 ...           ...   \n",
       "294  no aguardo da proposta milionária na dm pra co...   Irrelevante   \n",
       "295  puma, chuteira preta hmm\\nfedeu a hexa https:/...   Irrelevante   \n",
       "296  serase o @neymarjr vai ressarcir meu dinheiro ...   Irrelevante   \n",
       "297  só jogo lixo às 16hrs nessa rodada do br.\\n\\né...   Irrelevante   \n",
       "298  voces gostaram da nova chuteira do neymar com ...   Irrelevante   \n",
       "\n",
       "    classificador  \n",
       "0       Relevante  \n",
       "1       Relevante  \n",
       "2       Relevante  \n",
       "3       Relevante  \n",
       "4       Relevante  \n",
       "..            ...  \n",
       "294     Relevante  \n",
       "295     Relevante  \n",
       "296     Relevante  \n",
       "297   Irrelevante  \n",
       "298     Relevante  \n",
       "\n",
       "[299 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['classificador'] = classificador\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificador</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classificacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.497959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.502041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificador  Irrelevante  Relevante\n",
       "classificacao                        \n",
       "Irrelevante       0.685185   0.497959\n",
       "Relevante         0.314815   0.502041"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['classificacao'], test['classificador'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertou 68% dos irr\n",
    "acertou 50,2% dos re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
